---
title: ES面试总结 其一
date: 2023-09-17 20:49:58
tags: [Java,面试,ES,ElasticSearch]
categories: Java
---

# 什么是ES？

Elasticsearch（简称为ES）是一个开源的分布式搜索和分析引擎，最初由Elastic公司开发并维护。它被设计用于处理大规模数据集，具有强大的全文搜索、实时数据分析和日志存储等功能。Elasticsearch广泛用于各种应用领域，包括搜索引擎、日志和事件数据分析、安全信息与事件管理（SIEM）、电子商务平台、监控和性能优化等。

以下是Elasticsearch的一些关键特点和功能：

1. **全文搜索：** Elasticsearch支持强大的全文搜索功能，能够高效地处理文本数据的搜索和匹配。它使用倒排索引来实现快速的文本检索。

2. **分布式架构：** Elasticsearch是一个分布式系统，可以水平扩展以处理大规模数据和高负载。它将数据分片存储在多个节点上，实现了高可用性和容错性。

3. **实时性：** Elasticsearch支持实时索引和查询，能够在数据发生变化时立即反映在搜索结果中，因此非常适合实时数据处理和监控应用。

4. **多种数据类型支持：** Elasticsearch不仅支持文本数据，还支持结构化数据、地理位置数据、数字数据等多种数据类型的索引和搜索。

5. **复杂查询：** Elasticsearch提供了丰富的查询DSL（领域特定语言），允许用户进行复杂的查询和过滤，包括全文搜索、精确匹配、范围查询、聚合查询等。

6. **多语言支持：** Elasticsearch支持多种编程语言的客户端，使开发者能够轻松地与Elasticsearch进行交互。

7. **开放源代码：** Elasticsearch是开源的，基于Apache许可证发布，可以免费使用和定制。

8. **生态系统：** Elasticsearch具有丰富的生态系统，包括Kibana（用于数据可视化和仪表板）、Logstash（用于数据收集和处理）、Beats（用于轻量级数据采集器）等工具，组成了Elastic Stack（ELK Stack）。

总之，Elasticsearch是一个功能强大且高度可定制的搜索和分析引擎，被广泛用于处理各种类型的数据，从文本搜索到日志分析和业务智能。它的灵活性和性能使其成为许多企业和开发者的首选工具之一。

# ES有哪些基本的概览？它的集群是如何构成的？单个节点又是如何构成的？

Elasticsearch（ES）的基本概览包括了其集群和单个节点的构成，让我们一起来了解它们：

**集群（Cluster）：**
- 一个Elasticsearch集群是由一个或多个节点组成的，它们协同工作以存储和处理数据。
- 集群有一个唯一的名称，允许多个集群在同一个网络中运行而不会互相干扰。
- 集群中的节点可以动态加入或离开，实现了高可用性和水平扩展。
- 集群中的节点可以分布在不同的物理机器上，以分散负载和提高容错性。

**节点（Node）：**
- 一个Elasticsearch节点是集群中的一个单独的实例，负责存储数据、执行搜索和处理请求。
- 节点有一个唯一的名称，通常由随机生成的名字组成。
- 每个节点都知道集群中的其他节点，并可以与它们通信。
- 节点可以配置为存储数据（数据节点）或仅执行搜索和计算（客户端节点）。
- 集群中至少有一个主节点（Master Node）负责集群的管理，如节点的加入和离开以及分片的分配。在主节点失败时，可以选举出新的主节点。

**数据存储和分片：**
- Elasticsearch将数据分为多个分片（Shard），每个分片可以是主分片或复制分片（Replica）。
- 主分片存储数据的原始副本，复制分片是主分片的副本，用于提供高可用性。
- 分片可以在不同的节点上分布，从而实现了数据的分布式存储和查询。
- Elasticsearch通过分片和复制来实现数据的分散存储和容错性。

**数据索引：**
- 数据在Elasticsearch中以索引的形式存储，每个索引包含一个或多个分片。
- 索引定义了数据的结构和映射，允许您执行各种查询和分析。
- 每个文档都属于一个索引，文档可以通过其唯一的ID进行检索。
- Elasticsearch支持多种数据类型的索引，包括全文搜索、地理位置数据、数字数据等。

总结：Elasticsearch是一个分布式的搜索和分析引擎，集群由多个节点组成，节点之间协同工作以存储和处理数据。每个节点可以存储数据并执行搜索，数据以索引的形式存储，每个索引包含多个分片和复制分片，实现了数据的分布式存储和高可用性。这种架构使Elasticsearch非常适合处理大规模数据和高负载的应用场景。

# 什么是倒排索引？

倒排索引（Inverted Index）是一种用于文本搜索和信息检索的数据结构，它的设计目标是快速地查找包含特定词条（或关键词）的文档。倒排索引与传统的索引方式相反，它将文档中的词条映射到文档的位置，而不是将文档映射到词条。

以下是倒排索引的基本工作原理和关键概念：

1. **文档收集：** 在构建倒排索引之前，首先需要收集和准备要索引的文档集合。文档可以是任何形式的文本，例如网页、文档、电子邮件、日志等。

2. **文档分词：** 对每个文档进行分词处理，将文本分解成独立的词条（或标记）。分词过程通常包括去除停用词、词干提取、小写化等处理。

3. **词条映射：** 对每个词条建立索引，将每个词条映射到包含该词条的文档列表。这个映射关系存储在倒排索引中。

4. **查询处理：** 当执行搜索查询时，查询的关键词也会进行分词处理，并在倒排索引中查找包含这些关键词的文档列表。

5. **结果排序：** 根据查询的相关性，对匹配的文档进行排序，通常使用评分算法来确定文档的相关性得分。

倒排索引的主要优点是快速的搜索性能。当您需要搜索包含特定关键词的文档时，倒排索引允许您只查找包含这些关键词的文档，而不需要扫描所有文档。这种索引结构在全文搜索引擎（如Elasticsearch和Solr）中得到广泛应用，用于构建高效的文本搜索引擎和信息检索系统。

# 哪些字段类型会生成DocValues?

在Elasticsearch中，不是所有字段类型都会生成DocValues。DocValues通常与用于排序、聚合和过滤的字段相关联。以下是一些字段类型，通常会生成DocValues：

1. **Keyword Field（关键词字段）：** Keyword字段存储不会被分词的完整文本，通常用于精确匹配、排序和聚合。它们生成DocValues以支持排序和快速过滤。

2. **Numeric Fields（数字字段）：** 数字字段（如整数、浮点数、日期等）存储数值数据，可以用于排序和聚合。它们生成DocValues以支持数值排序和聚合操作。

3. **Date Field（日期字段）：** 日期字段存储日期和时间信息，通常用于按日期排序和聚合。它们生成DocValues以支持日期排序和时间范围过滤。

4. **Boolean Field（布尔字段）：** 布尔字段存储布尔值（true或false），通常用于过滤。它们生成DocValues以支持布尔过滤操作。

5. **GeoPoint Field（地理位置字段）：** 地理位置字段存储地理坐标，通常用于地理空间搜索和距离计算。它们生成DocValues以支持地理位置过滤和距离计算。

需要注意的是，文本字段（Text Field）通常不会生成DocValues，因为它们用于全文搜索，而不是排序和聚合。对于全文搜索，通常使用倒排索引来实现。如果需要在文本字段上执行排序、聚合或精确匹配等操作，可以使用Keyword字段或将Text字段显式设置为生成DocValues。

总之，生成DocValues的字段类型通常包括关键词字段、数字字段、日期字段、布尔字段和地理位置字段，这些字段用于支持排序、聚合和过滤等操作。在索引映射中可以明确指定哪些字段需要生成DocValues。

# text和keyword的区别？

在Elasticsearch中，`text` 和 `keyword` 是两种不同的字段类型，它们有不同的用途和特性。以下是它们的主要区别：

1. **存储方式：**
   - `text` 字段用于全文搜索。它将文本内容分析成单词（或词项），并构建倒排索引，以支持文本搜索。`text` 字段通常用于包含文本内容的字段，例如文章正文、评论、描述等。
   - `keyword` 字段存储未经分析的完整文本。它不会将文本拆分成单词，而是将整个文本作为一个关键词存储。`keyword` 字段通常用于精确匹配、排序和聚合，例如标签、分类、城市名称等。

2. **分析过程：**
   - `text` 字段会经过分词（Tokenization）和文本分析（Text Analysis）处理。这意味着文本会被拆分成单词，然后进行小写化、词干提取、停用词移除等处理。
   - `keyword` 字段不会经过分词和文本分析，它保留文本的原始形式，完整存储。

3. **搜索行为：**
   - `text` 字段适用于全文搜索，支持模糊搜索、部分匹配和词项匹配等。它通常用于用户输入的搜索查询。
   - `keyword` 字段适用于精确匹配，只能通过完全匹配字段的值来搜索。它通常用于不需要分析和模糊匹配的场景。

4. **排序和聚合：**
   - `text` 字段通常不用于排序和聚合，因为它包含了大量的词项，难以确定如何排序或聚合。
   - `keyword` 字段适用于排序和聚合，因为它存储了原始文本，可以直接进行排序和聚合操作。

5. **存储空间：**
   - `text` 字段通常占用更多的存储空间，因为它会生成倒排索引和分析数据。
   - `keyword` 字段通常占用较少的存储空间，因为它仅存储原始文本。

总结来说，`text` 适用于全文搜索和模糊匹配的场景，而 `keyword` 适用于精确匹配、排序和聚合的场景。在索引设计中，需要根据字段的用途和搜索需求来选择合适的字段类型。有时，还可以在同一文本数据上同时使用 `text` 和 `keyword` 字段以满足不同的需求。

# 什么是停顿词过滤？

停顿词过滤（Stop Word Filtering）是文本处理中的一项常见技术，用于从文本中删除那些被认为是对文本分析无关紧要的常见词汇，这些词汇通常称为停顿词（Stop Words）。停顿词通常是语言中的常见单词，如 "a," "an," "the," "in," "on," "at," "is," "and," "of" 等。

停顿词过滤的主要目的是减小文本数据的维度，提高文本处理的效率，并在某些情况下改善文本搜索和分析的结果。以下是停顿词过滤的一些关键概念和作用：

1. **删除常见词汇：** 停顿词过滤会从文本中删除出现频率极高但通常对搜索和分析无帮助的常见词汇。这些词汇不包含足够的信息来支持有意义的搜索和分析。

2. **减小索引大小：** 在全文搜索引擎和信息检索系统中，文本索引通常需要占用大量的存储空间。通过删除停顿词，可以显著减小索引的大小，从而降低存储和内存消耗。

3. **提高查询性能：** 由于索引较小，因此对文本数据执行搜索和查询操作时通常更快。此外，减少了索引的大小，可以降低磁盘IO和内存消耗，提高性能。

4. **改善搜索质量：** 在某些情况下，删除停顿词可以改善搜索结果的质量。例如，在某些搜索场景中，用户可能会输入一个问题或短语，而停顿词通常不会对搜索结果产生显著影响。

需要注意的是，停顿词的定义通常取决于特定的应用和语言，因为在某些上下文中，某些词汇可能是有用的。因此，在进行停顿词过滤时，需要谨慎选择停顿词列表，以确保不会删除对特定搜索和分析任务有用的词汇。在某些情况下，还可以根据具体需求自定义停顿词列表。

# query和filter有何区别？

在Elasticsearch中，`query` 和 `filter` 是两种用于构建查询的不同方式，它们在功能和用途上有一些重要的区别。

1. **Query（查询）：**
   - `query` 主要用于定义搜索条件，并确定文档的相关性得分（Relevance Score）。它会影响搜索结果的排序，使得与查询条件匹配度更高的文档排在前面。
   - 查询可以包括全文搜索、模糊搜索、短语匹配、前缀搜索等，以及各种查询类型（如布尔查询、范围查询、模糊查询等）。
   - 查询的结果会按照相关性得分（Score）排序，默认情况下，文档得分越高的排名越靠前。

2. **Filter（过滤）：**
   - `filter` 用于精确地筛选文档，通常不会影响文档的相关性得分。过滤器主要用于将文档限制在满足特定条件的范围内，而不会改变文档的排序顺序。
   - 过滤器通常用于处理精确匹配、范围匹配、布尔条件等，并且不会计算相关性得分。
   - 过滤器可以提高查询性能，因为它们不需要计算相关性得分，通常会被缓存以提供更快的查询速度。

关键区别：
- `query` 会影响文档的相关性得分，而 `filter` 不会影响得分。
- `query` 通常用于全文搜索和复杂的查询条件，而 `filter` 用于精确匹配和筛选。
- `filter` 通常比 `query` 更快，因为它们可以被缓存，并且不需要计算得分。

通常，您可以根据查询的性质来选择使用 `query` 或 `filter`。如果您希望根据文档的相关性对结果排序，使用 `query`；如果您只需要筛选出满足特定条件的文档，而不关心排序，使用 `filter`。此外，使用 `filter` 可以减少查询的计算成本，从而提高性能。

# ES写入数据的整个过程是怎么样的？

![img](https://pic2.zhimg.com/v2-3450e1712198e01c3b97d32604dee275_r.jpg)

- 首先客户端会根据配置的连接节点，通过轮询的方式选择一个coordinate节点。
- coordinate节点通过路由函数（`shard = hash(routing)%number_of_primary_shards`），计算出数据应该落到那个shard中，根据coordinate节点上维护的shard信息，将请求发送到Node1上。
- Node1先校验索引数据，然后在主分片上执行请求，执行成功后，将请求并行转发到副本集存在Node2、Node3。
- Node2、Node3写入成功数据成功后，发送ack信息给主分片所在的Node1节点。
- Node1节点再将ack信息发送给coordinate节点。
- coordinate 节点 发送ack节点给客户端。

在主分片上执行写入请求的过程如下：

![img](https://pic1.zhimg.com/v2-13a14948e55493d9140df0614c0ad63c_r.jpg)

1. 当有数据写入时，为了提升写速度，也是先将数据写入到内存（Memory Buffer）中的；
2. 因为先写入了内存所以为了保证内存中的数据不丢失，也会同时写入Translog到内存中。
3. 每隔一定时间（可配置）将数据从Memory Buffer中`refresh`到`FileSystemCache`中，生成**segment**文件，一旦生成segment文件，就能通过索引查询到了。
4. refresh完，memory buffer就清空了。Translog 也是从buffer flush到磁盘中。
5. 定期/定量从FileSystemCache中,结合Translog内容flush index到磁盘中。做增量flush的。

因为Elasticsearch的这个刷盘机制，也说明并非是一个实时的搜索引擎。

# 为什么说ES是近实时系统?

Elasticsearch（ES）被称为"近实时"系统，是因为它具有一些特性和限制，使得它在处理数据时表现得几乎是实时的，但并不是真正的实时系统。以下是解释为什么ES被称为近实时系统的一些原因：

1. **数据写入延迟：** 当数据写入Elasticsearch时，它首先被缓存在内存中，而不是立即写入磁盘。这是为了提高写入性能。这意味着在数据写入到磁盘之前，存在一些微小的延迟，通常为几百毫秒。

2. **刷新和提交：** Elasticsearch采用了刷新（flush）和提交（commit）机制，定期将内存中的数据刷新到磁盘上。刷新和提交的频率可以配置，但默认情况下是每秒一次。这意味着在刷新之前，写入的数据可能会在内存中暂时存储，因此在刷新之前数据不会被持久化到磁盘。

3. **文档级别的实时性：** 对于单个文档的写入操作，Elasticsearch通常可以提供几乎实时的响应。这意味着一旦文档写入成功，它几乎立即可用于搜索。这种文档级别的实时性是ES的一个强大特性。

4. **批量写入和索引刷新：** 对于大批量数据的写入，ES允许批量索引操作，但这些操作可能需要一段时间来执行。在这种情况下，数据可能需要等待批量操作完成后才能被搜索。

总之，虽然Elasticsearch可以提供接近实时的查询和文档级别的实时性，但它并不是一个严格的实时系统，因为它有一些内部机制和延迟，以优化性能和可靠性。这种近实时的性能使ES成为处理实时搜索和分析的强大工具，但在某些特定场景下，可能需要更严格的实时性能，这时需要考虑其他技术和工具。

# ES的索引为什么是不可变的呢?

Elasticsearch中的索引是不可变的，这是出于性能、数据一致性和分布式系统的考虑而设计的。以下是索引不可变性的一些原因：

1. **性能优化：** 不可变性使得索引的读操作和写操作能够并行进行，而不需要锁定索引或复杂的同步机制。这提高了性能，允许多个读操作同时进行，而不会受到写操作的干扰。

2. **数据一致性：** 不可变性确保了索引的数据一致性。一旦文档被索引，它就不会被修改，而是通过标记为已删除或创建新版本的方式来更新。这种不可变性使得Elasticsearch能够更容易地实现ACID（原子性、一致性、隔离性和持久性）特性，确保数据的可靠性。

3. **版本控制：** 每个文档都有一个唯一的版本号，用于跟踪文档的修改历史。当需要更新文档时，Elasticsearch会创建一个新版本，而不是修改原始文档。这种版本控制使得能够查询不同版本的文档，同时保留了历史数据。

4. **分布式复制：** 不可变性使得分布式复制更加简单和可靠。副本分片只需要复制主分片的内容，而不需要考虑文档的修改。这简化了分布式复制的实现。

5. **数据安全性：** 不可变性提高了数据的安全性。一旦文档被索引，它不能被随意修改或删除。这对于满足合规性要求和数据完整性非常重要。

虽然索引是不可变的，但Elasticsearch提供了强大的查询和索引重建功能，以便有效地处理数据的变化和查询需求。索引别名、索引模板和索引生命周期策略等功能可以帮助管理和维护索引，以适应不断变化的数据需求。因此，尽管索引是不可变的，但Elasticsearch仍然提供了灵活性和高性能的数据管理机制。

# ES是如何保证高可用呢？

Elasticsearch（ES）通过多种机制来确保高可用性，使得数据在节点故障或其他问题时仍然可用。以下是ES保证高可用性的主要方法：

1. **分片和副本：** Elasticsearch将每个索引分成若干主分片和零个或多个副本分片。主分片负责原始数据的存储，而副本分片提供数据的冗余和容错能力。如果主分片所在的节点发生故障，ES会自动从副本分片中提升一个新的主分片，确保数据的可用性。

2. **分布式架构：** Elasticsearch是一个分布式系统，数据分布在多个节点上。这意味着即使一个或多个节点发生故障，集群仍然可以继续提供服务。集群的其他节点可以接管失效节点上的分片。

3. **节点自动发现：** ES节点可以通过自动发现功能加入和离开集群，这意味着新节点可以随时加入集群，而无需手动配置。这提高了可扩展性和容错性。

4. **负载均衡：** ES集群会自动分配主分片和副本分片到不同的节点上，以确保负载均衡。这有助于避免某些节点过度负载，提高性能和可用性。

5. **快速恢复：** 当节点重新加入集群或替代节点时，ES能够快速地恢复数据。这包括从其他节点或副本分片中获取数据，以便在节点故障后迅速恢复。

6. **监控和警报：** ES提供了丰富的监控和警报功能，允许管理员实时监视集群的状态和性能。这有助于及时发现并解决潜在的问题，提高可用性。

7. **索引重建：** 如果索引发生问题，ES允许索引的重建。这意味着可以从主分片和副本分片中重新创建索引，以修复损坏的数据。

8. **外部负载均衡：** 在生产环境中，通常会使用外部负载均衡器来均衡流量并分发请求到多个ES节点。这进一步提高了可用性和负载均衡性能。

总之，Elasticsearch通过分片、副本、分布式架构、自动发现、快速恢复和监控等多种机制来确保高可用性。这些特性使ES成为处理大规模数据的可靠工具，能够在节点故障或其他问题发生时保持数据的可用性和稳定性。

# ES是如何保证高并发下读写一致的呢？

Elasticsearch（ES）通过一系列机制来保证在高并发下读写一致性，确保数据的可靠性和正确性。以下是ES实现高并发下读写一致性的主要方法：

1. **分布式写入和复制：** ES使用分片（Shard）来存储数据，并通过主分片和副本分片的机制来提供数据冗余和高可用性。写入操作首先写入主分片，然后复制到副本分片上。这确保了写入的一致性和持久性，即使主分片所在的节点发生故障，数据仍然可以从副本分片中恢复。

2. **数据同步机制：** 当数据写入主分片后，ES会通过复制机制将数据同步到副本分片上。数据的复制过程是异步的，但ES确保数据在主分片和副本分片之间达到一定程度的一致性。这意味着写入操作在成功返回之前，主分片和副本分片的数据应该是一致的。

3. **刷新和提交：** ES定期执行刷新（Flush）和提交（Commit）操作，将内存中的数据刷新到磁盘上。刷新和提交操作会将数据持久化到磁盘，并确保数据的一致性。这意味着在数据刷新之前，写入的数据会暂时存储在内存中，但它们最终会被持久化到磁盘，从而提供了数据的持久性和一致性。

4. **文档版本控制：** 每个文档都有一个唯一的版本号，用于跟踪文档的修改历史。当需要更新文档时，ES会创建一个新版本，而不是修改原始文档。这种版本控制机制确保了写入操作的一致性，并允许查询不同版本的文档。

5. **并发控制：** ES使用乐观并发控制（Optimistic Concurrency Control）来处理并发写入冲突。每个文档都有一个版本号，写入操作会检查文档的版本号，如果版本号匹配，写入操作将被接受，否则会被拒绝。这确保了数据的一致性，避免了不同客户端之间的写入冲突。

总之，Elasticsearch通过分布式写入、复制、数据同步、刷新和提交、版本控制和并发控制等多种机制来保证在高并发下读写一致性。这些机制一起确保了数据的可靠性、一致性和可用性，使ES成为处理大规模数据的可靠工具。

# 讲讲ES的乐观锁？

Elasticsearch 7.0 版本引入了 `seq_no`（sequence number）和 `primary_term`（primary term）来替代之前版本中的文档版本号。这一变化旨在提高版本控制的灵活性和可靠性。

- `seq_no`：`seq_no`是一个递增的整数，用于标识文档的修改顺序。每次文档被修改时，`seq_no`都会自动递增。它用于解决文档的更新顺序问题，确保了文档的修改操作按照正确的顺序进行。

- `primary_term`：`primary_term`是一个递增的整数，用于标识文档的版本。在主分片（primary shard）中的文档在每次分片的重新分配或主分片发生变化时，都会增加 `primary_term`。它用于解决分片的变更问题，确保在分片发生变更时不会发生版本冲突。

这种改变可以更好地支持分布式系统中的文档协调和版本控制，尤其是在分片重新分配或主分片切换时。虽然文档的版本号在某种程度上仍然存在，但`seq_no`和`primary_term`提供了更准确和可靠的方式来处理文档的修改历史和分布式情况下的一致性。

需要注意的是，`seq_no`和`primary_term`在处理版本控制和冲突解决时可能需要不同的逻辑，开发人员需要了解这些新的版本控制机制，并相应地更新他们的应用程序来适应这些变化。

# 讲讲ES的主节点选举过程？

在 Elasticsearch（ES）集群中，主节点选举是为了确定哪个节点将充当集群的主节点，主节点负责协调集群的操作和管理元数据。主节点的选举过程如下：

1. **节点加入集群：** 当一个新节点加入集群或一个现有节点重新启动时，它将尝试加入集群，并与集群中的其他节点建立通信。

2. **节点发现：** 新节点或重新启动的节点将通过网络发现集群中的其他节点。这通常涉及到使用配置中指定的种子节点列表，从而找到集群中的节点。

3. **选举触发：** 当节点成功加入集群后，它将与其他节点一起参与主节点选举。选举通常在以下几种情况下触发：

   - 集群初始启动：在集群初始化阶段，没有现有主节点，因此需要进行首次选举。
   - 主节点故障：如果当前的主节点发生故障或不可用，集群将触发新一轮的主节点选举。
   - 新节点加入：当新节点加入集群时，它会尝试成为主节点，从而触发选举。

4. **选举算法：** 主节点选举通常采用的是分布式选举算法，Elasticsearch中使用的是Zen Discovery算法。Zen Discovery会根据节点的状态和性能指标来选择新的主节点。通常情况下，具有较高性能和稳定性的节点更有可能成为主节点。

5. **选举结果：** 最终，一个节点将被选举为新的主节点，其余节点将成为从节点。主节点负责集群管理、协调分片分配、维护集群状态等任务。

需要注意的是，主节点选举是集群中的一种分布式决策过程，它确保了在主节点故障或新节点加入时集群能够继续正常工作。主节点的选举过程通常是自动的，不需要管理员手动干预。同时，主节点选举的稳定性和性能对于整个集群的正常运行非常重要。因此，节点的硬件性能、网络稳定性以及集群配置都可能影响主节点选举的结果。

# 什么是脑裂？ES如何避免脑裂？

脑裂（Split Brain）是分布式系统中一种常见的问题，它发生在一个分布式系统中的节点之间失去了通信或网络分区导致的情况下。脑裂可能会导致系统的不一致性和故障，因为节点之间无法达成一致的共识。在 Elasticsearch（ES）中，脑裂是一个需要特别注意的问题，因为它可能导致数据丢失或集群分裂成多个独立的子集群。

脑裂可能出现以下情况之一：

1. **网络分区：** 当一个 Elasticsearch 集群中的节点之间的网络通信出现问题时，可能会发生网络分区。这意味着集群中的一部分节点无法与其他节点通信，从而导致分区内部的节点形成一个新的子集群。

2. **节点故障：** 如果某个节点崩溃或变得不可用，其他节点可能会认为该节点已经脱离了集群，从而形成分区。

3. **主节点选举冲突：** 在 Elasticsearch 中，主节点的选举是通过多数投票来决定的。如果存在两个或更多的候选主节点，它们中的一个可能会获得多数投票，成为主节点，而其他节点可能会认为自己已经脱离了集群，导致分区。

为了避免脑裂问题，Elasticsearch 采取了以下策略：

1. **Quorum：** Elasticsearch 要求在主节点选举和分片分配等关键决策中需要多数节点的支持。这意味着在一个有 N 个节点的集群中，至少需要 N/2 + 1 个节点的支持才能进行决策。这有助于防止在网络分区或节点故障情况下出现脑裂。

2. **Zen Discovery：** Elasticsearch 使用 Zen Discovery 机制来检测网络分区和节点失效，并尝试避免脑裂。Zen Discovery 会动态调整节点的选举权重，确保在网络分区情况下只有一个子集群的节点能够成为主节点。

3. **Minimum Master Nodes 设置：** 配置中的 `discovery.zen.minimum_master_nodes` 参数用于定义集群中必须具备的主节点数量。这个参数的正确设置可以防止脑裂问题。

4. **Quorum-based Voting：** Elasticsearch 在主节点选举中采用了基于多数投票的机制，确保只有得到多数节点支持的节点才能成为主节点。

总之，Elasticsearch 通过配置和内置的机制来尽量避免脑裂问题。在配置集群时，合理设置参数和监控节点状态对于防止脑裂问题非常重要。当然，对于关键的生产环境，还可以采用硬件冗余、网络配置优化等方式来提高系统的稳定性和可用性。

# ES的搜索流程？

ES的搜索流程可以分为两个主要阶段：Query 阶段和 Fetch 阶段。

1. **Query（查询）阶段**：
   - 在分片级别的查询中，这个阶段包括倒排索引匹配、评分和排序。
   - 倒排索引匹配：在查询阶段，Elasticsearch使用倒排索引快速查找匹配查询条件的文档。这是查询阶段的核心，它确定了哪些文档包含了查询的关键词。
   - 评分和排序：匹配的文档会根据其相关性得分进行排序。这个阶段决定了搜索结果的顺序，将最相关的文档排在前面。Elasticsearch使用TF-IDF、BM25等算法来计算文档的得分。

2. **Fetch（提取）阶段**：
   - 在分片级别的查询之后，Elasticsearch将匹配的文档从磁盘中提取出来，以便将它们返回给客户端。
   - 这个阶段包括从磁盘读取文档数据，通常是文档的原始JSON或其他格式。
   - 在Fetch阶段，不再计算文档的相关性得分或进行排序，因为这些操作已经在Query阶段完成。Fetch阶段的任务是返回文档数据本身。

总之，Query阶段涉及到查询的执行、文档的匹配和相关性得分的计算，而Fetch阶段涉及到从磁盘中提取匹配的文档数据。这两个阶段一起协作，使Elasticsearch能够高效地处理搜索请求并返回相关的结果。
